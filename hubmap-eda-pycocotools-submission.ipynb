{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.ibb.co/7t6wKN7/000.png)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Exploratory Data Analysis  ðŸ“š</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>EDA Libraries âš’</b>\n</div>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport numpy as np\nimport os \nimport pandas as pd \nfrom tqdm import tqdm, notebook \nfrom collections import Counter\nimport warnings ","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:39.776578Z","iopub.execute_input":"2023-06-27T14:44:39.777007Z","iopub.status.idle":"2023-06-27T14:44:39.890311Z","shell.execute_reply.started":"2023-06-27T14:44:39.776974Z","shell.execute_reply":"2023-06-27T14:44:39.889117Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:41.428554Z","iopub.execute_input":"2023-06-27T14:44:41.428978Z","iopub.status.idle":"2023-06-27T14:44:41.434983Z","shell.execute_reply.started":"2023-06-27T14:44:41.428946Z","shell.execute_reply":"2023-06-27T14:44:41.433685Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Pathes ðŸ§¶</b>\n</div>","metadata":{}},{"cell_type":"code","source":"# Files \n__SAMPLE_SBMISSION_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/sample_submission.csv\"\n__TILE_META_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/tile_meta.csv\"\n__WSI_META_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/wsi_meta.csv\"\n__ANNOTATION_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/polygons.jsonl\"\n__DATASET_CONFIG_PATH = \"/kaggle/working/classes_config.csv\" # Custom file\n\n# Folders\n__TRAIN_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/train\"\n__TEST_PATH = \"/kaggle/input/hubmap-hacking-the-human-vasculature/test\"","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:43.318532Z","iopub.execute_input":"2023-06-27T14:44:43.319016Z","iopub.status.idle":"2023-06-27T14:44:43.325703Z","shell.execute_reply.started":"2023-06-27T14:44:43.318978Z","shell.execute_reply":"2023-06-27T14:44:43.324378Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(__SAMPLE_SBMISSION_PATH)\ntile_meta = pd.read_csv(__TILE_META_PATH)\nwsi_meta = pd.read_csv(__WSI_META_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:46.041462Z","iopub.execute_input":"2023-06-27T14:44:46.041851Z","iopub.status.idle":"2023-06-27T14:44:46.095625Z","shell.execute_reply.started":"2023-06-27T14:44:46.041824Z","shell.execute_reply":"2023-06-27T14:44:46.094541Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Sample submission ðŸ“©</b>\n</div>","metadata":{}},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:47.572290Z","iopub.execute_input":"2023-06-27T14:44:47.572748Z","iopub.status.idle":"2023-06-27T14:44:47.606784Z","shell.execute_reply.started":"2023-06-27T14:44:47.572718Z","shell.execute_reply":"2023-06-27T14:44:47.605278Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"             id  height  width                   prediction_string\n0  72e40acccadf     512    512  0 1.0 eNoLTDAwyrM3yI/PMwcAE94DZA==","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>height</th>\n      <th>width</th>\n      <th>prediction_string</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>72e40acccadf</td>\n      <td>512</td>\n      <td>512</td>\n      <td>0 1.0 eNoLTDAwyrM3yI/PMwcAE94DZA==</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<div class=\"sc-dmLtQE jWwnsR\"><p>\n<h2>Submission File</h2>\n<p>For each image in the test set, you must predict a list of instance segmentation masks and their associated detection score (<code>Confidence</code>). The <code>submission.csv</code> file uses the following format:</p>\n<pre><code><span class=\"hljs-attribute\">id</span>,height,width,prediction_string\n<span class=\"hljs-attribute\">72e40acccadf</span>,<span class=\"hljs-number\">512</span>,<span class=\"hljs-number\">512</span>,<span class=\"hljs-number\">0</span> <span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">0</span> eNoLTDAwyrM3yI/PMwcAE94DZA==\n</code></pre>\n<p>where <code>prediction_string</code> has the format <code>0 {confidence} {EncodedMask}</code>. Note that the metric has several \"boilerplate\" values needed to adapt it to this competition; namely, the <code>height</code>, <code>width</code>, and the leading <code>0</code> in <code>prediction_string</code>, which ordinarily is a class label.</p>\n<p>Separate prediction strings multiple instance masks for the same image with a space, like so:</p>\n<pre><code><span class=\"hljs-attribute\">id</span>,height,width,prediction_string\n<span class=\"hljs-attribute\">72e40acccadf</span>,<span class=\"hljs-number\">512</span>,<span class=\"hljs-number\">512</span>,<span class=\"hljs-number\">0</span> <span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">0</span> eNoLTDAwyrM3yI/PMwcAE94DZA== <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">0</span>.<span class=\"hljs-number\">5</span> eAndnnDS1A/mdmkE35Ek9d\n</code></pre>\n<p>The binary segmentation masks are <a rel=\"noreferrer nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Run-length_encoding\">run-length encoded</a> (RLE), <a rel=\"noreferrer nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Zlib\">zlib</a> compressed, and <a rel=\"noreferrer nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Base64\">base64</a> encoded to be used in text format as <code>EncodedMask</code>. Specifically, we use the Coco masks RLE encoding/decoding (see the <code>encode</code> method of <a rel=\"noreferrer nofollow\" target=\"_blank\" href=\"http://cocodataset.org/#download\">COCOâ€™s mask API</a>), the zlib compression/decompression (<a rel=\"noreferrer nofollow\" target=\"_blank\" href=\"https://www.ietf.org/rfc/rfc1950.txt\">RFC1950</a>), and vanilla base64 encoding.</p>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Tile meta</b>\n</div>","metadata":{}},{"cell_type":"code","source":"tile_meta","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:51.316596Z","iopub.execute_input":"2023-06-27T14:44:51.317042Z","iopub.status.idle":"2023-06-27T14:44:51.333634Z","shell.execute_reply.started":"2023-06-27T14:44:51.316994Z","shell.execute_reply":"2023-06-27T14:44:51.332210Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                id  source_wsi  dataset      i      j\n0     0006ff2aa7cd           2        2  16896  16420\n1     000e79e206b7           6        3  10240  29184\n2     00168d1b7522           2        2  14848  14884\n3     00176a88fdb0           7        3  14848  25088\n4     0033bbc76b6b           1        1  10240  43008\n...            ...         ...      ...    ...    ...\n7028  ffd37b5c6598          13        3  13824  21504\n7029  ffd3d193c71e           3        2   7680  16896\n7030  ffd77e2517af          13        3  15872  28160\n7031  ffe3cbb81f72          10        3  15456  23000\n7032  ffe40e3bc324           9        3  13824  19456\n\n[7033 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>source_wsi</th>\n      <th>dataset</th>\n      <th>i</th>\n      <th>j</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0006ff2aa7cd</td>\n      <td>2</td>\n      <td>2</td>\n      <td>16896</td>\n      <td>16420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000e79e206b7</td>\n      <td>6</td>\n      <td>3</td>\n      <td>10240</td>\n      <td>29184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00168d1b7522</td>\n      <td>2</td>\n      <td>2</td>\n      <td>14848</td>\n      <td>14884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00176a88fdb0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>14848</td>\n      <td>25088</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0033bbc76b6b</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10240</td>\n      <td>43008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7028</th>\n      <td>ffd37b5c6598</td>\n      <td>13</td>\n      <td>3</td>\n      <td>13824</td>\n      <td>21504</td>\n    </tr>\n    <tr>\n      <th>7029</th>\n      <td>ffd3d193c71e</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7680</td>\n      <td>16896</td>\n    </tr>\n    <tr>\n      <th>7030</th>\n      <td>ffd77e2517af</td>\n      <td>13</td>\n      <td>3</td>\n      <td>15872</td>\n      <td>28160</td>\n    </tr>\n    <tr>\n      <th>7031</th>\n      <td>ffe3cbb81f72</td>\n      <td>10</td>\n      <td>3</td>\n      <td>15456</td>\n      <td>23000</td>\n    </tr>\n    <tr>\n      <th>7032</th>\n      <td>ffe40e3bc324</td>\n      <td>9</td>\n      <td>3</td>\n      <td>13824</td>\n      <td>19456</td>\n    </tr>\n  </tbody>\n</table>\n<p>7033 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset_count = tile_meta['dataset'].value_counts()\n\nplt.bar(list(map(str, dataset_count.index)), dataset_count.values)\n\nplt.xlabel('Dataset Number')\nplt.ylabel('Number of Examples')\nplt.title('Number of examples in each dataset')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:52.389616Z","iopub.execute_input":"2023-06-27T14:44:52.390050Z","iopub.status.idle":"2023-06-27T14:44:52.675124Z","shell.execute_reply.started":"2023-06-27T14:44:52.390017Z","shell.execute_reply":"2023-06-27T14:44:52.673887Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Wsi meta</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #f0c7c7; font-family:verdana; color: #a63c3c; border: 2px #a63c3c solid\">\n    <br>Whole Slide Images (WSIs), also known as virtual slides or digital slides, refer to high-resolution digital representations of entire histopathology glass slides. These slides are typically generated by scanning glass slides using specialized slide scanners.<br>\n    <br>We should expect 14 unique sources of WSIs where 5 have been used for annotations by either a expert or non expert which then get put into dataset 1 and 2 respectively, and the other 9 correspond to WSIs for dataset 3 which have no annotations. Although we should expect 14 we see that there is only thirteen. A keen eye would see that number 5 is missing. This is probably because the 5th WSI belongs to the first dataset and was removed from the dataset to be used as the test set.<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Distribution of WSI by datasets\n![](https://i.ibb.co/6Y1zJvv/001.png)","metadata":{}},{"cell_type":"markdown","source":"## Legend \n![](https://i.ibb.co/gghC5LZ/002.png)","metadata":{}},{"cell_type":"code","source":"wsi_meta","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:55.828915Z","iopub.execute_input":"2023-06-27T14:44:55.829385Z","iopub.status.idle":"2023-06-27T14:44:55.845519Z","shell.execute_reply.started":"2023-06-27T14:44:55.829334Z","shell.execute_reply":"2023-06-27T14:44:55.844417Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   source_wsi  age sex race  height  weight   bmi\n0           1   58   F    W   160.0    59.0  23.0\n1           2   56   F    W   175.2   139.6  45.5\n2           3   73   F    W   162.3    87.5  33.2\n3           4   53   M    B   166.0    73.0  26.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_wsi</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>race</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>bmi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>58</td>\n      <td>F</td>\n      <td>W</td>\n      <td>160.0</td>\n      <td>59.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>56</td>\n      <td>F</td>\n      <td>W</td>\n      <td>175.2</td>\n      <td>139.6</td>\n      <td>45.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>73</td>\n      <td>F</td>\n      <td>W</td>\n      <td>162.3</td>\n      <td>87.5</td>\n      <td>33.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>53</td>\n      <td>M</td>\n      <td>B</td>\n      <td>166.0</td>\n      <td>73.0</td>\n      <td>26.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sex_counts = wsi_meta.sex.value_counts()\nrace_counts = wsi_meta.race.value_counts()\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nax1.pie(sex_counts.values, labels=sex_counts.index, autopct='%1.1f%%')\nax1.set_title(\"Distribution of Sexes\")\n\nax2.pie(race_counts.values, labels=race_counts.index, autopct='%1.1f%%')\nax2.set_title(\"Distribution of races\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:44:57.128220Z","iopub.execute_input":"2023-06-27T14:44:57.128916Z","iopub.status.idle":"2023-06-27T14:44:57.364903Z","shell.execute_reply.started":"2023-06-27T14:44:57.128881Z","shell.execute_reply":"2023-06-27T14:44:57.362750Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Polygons-annotation ðŸŽ¯</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"****\n![](https://i.ibb.co/z4BQ2jH/Screenshot-from-2023-06-11-15-19-16.png)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #f0c7c7; font-family:verdana; color: #a63c3c; border: 2px #a63c3c solid\">\nPolygonal segmentation masks in JSONL format, available for Dataset 1 and Dataset 2. Each line gives JSON annotations for a single image with:<ul>\n<li><code>id</code> Identifies the corresponding image in <strong>train/</strong></li>\n<li><code>annotations</code>  A list of mask annotations with:</li>\n<li><code>type</code> Identifies the type of structure annotated:<ul>\n<li><code>blood_vessel</code> The target structure. Your goal in this competition is to predict these kinds of masks on the test set.</li>\n<li><code>glomerulus</code> A capillary ball structure in the kidney. These parts of the images were excluded from blood vessel annotation. You should ensure none of your test set predictions occur within glomerulus structures as they will be counted as false positives. Annotations are provided for test set tiles.</li>\n<li><code>unsure</code> A structure the expert annotators cannot confidently distinguish as a blood vessel.</li></ul></li>\n<li><code>coordinates</code> A list of polygon coordinates defining the segmentation mask.</li></ul></li>\n</div>\n\n****","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Setup Pipeline âš™ï¸</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #f0c7c7; font-family:verdana; color: #a63c3c; border: 2px #a63c3c solid\">\n    And now we will install pycocotools. \n    <br>This tool is needed for encoding masks and their subsequent evaluation.<br>\n    We will also set a random number generator for all frameworks.\n</div>","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\n\nimport shutil\nimport os\nimport sys\nfrom colorama import Fore","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:45:03.170625Z","iopub.execute_input":"2023-06-27T14:45:03.171675Z","iopub.status.idle":"2023-06-27T14:45:03.176600Z","shell.execute_reply.started":"2023-06-27T14:45:03.171630Z","shell.execute_reply":"2023-06-27T14:45:03.175253Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class SetupPipline:   \n    @staticmethod\n    def __pycocotools() -> None:\n        if not os.path.exists(\"/kaggle/working/packages\"):\n            shutil.copytree(\"/kaggle/input/hubmap-tools-ultralytics-and-pycocotools/pycocotools/pycocotools\", \"/kaggle/working/packages\")\n            os.chdir(\"/kaggle/working/packages/pycocotools-2.0.6/\")\n            os.system(\"python setup.py install\")\n            os.system(\"pip install . --no-index --find-links /kaggle/working/packages/\")\n            os.chdir(\"/kaggle/working\")\n\n    @staticmethod\n    def seed_everything(seed: int) -> None:\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n    \n    def __call__(self, seed: int = 42, pycoco: bool = True) -> None:\n        if pycoco:\n            self.__pycocotools()\n        if seed:\n            self.seed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:45:13.389990Z","iopub.execute_input":"2023-06-27T14:45:13.391061Z","iopub.status.idle":"2023-06-27T14:45:13.400457Z","shell.execute_reply.started":"2023-06-27T14:45:13.391020Z","shell.execute_reply":"2023-06-27T14:45:13.399232Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"%%capture\nsetup = SetupPipline()\nSEED: int = 42\nsetup(seed=SEED, pycoco=True)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-27T14:45:14.352649Z","iopub.execute_input":"2023-06-27T14:45:14.353087Z","iopub.status.idle":"2023-06-27T14:46:16.148353Z","shell.execute_reply.started":"2023-06-27T14:45:14.353052Z","shell.execute_reply":"2023-06-27T14:46:16.147196Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"running install\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"running bdist_egg\nrunning egg_info\nwriting pycocotools.egg-info/PKG-INFO\nwriting dependency_links to pycocotools.egg-info/dependency_links.txt\nwriting requirements to pycocotools.egg-info/requires.txt\nwriting top-level names to pycocotools.egg-info/top_level.txt\nreading manifest file 'pycocotools.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwriting manifest file 'pycocotools.egg-info/SOURCES.txt'\ninstalling library code to build/bdist.linux-x86_64/egg\nrunning install_lib\nrunning build_py\ncreating build\ncreating build/lib.linux-x86_64-3.10\ncreating build/lib.linux-x86_64-3.10/pycocotools\ncopying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.10/pycocotools\ncopying pycocotools/__init__.py -> build/lib.linux-x86_64-3.10/pycocotools\ncopying pycocotools/mask.py -> build/lib.linux-x86_64-3.10/pycocotools\ncopying pycocotools/coco.py -> build/lib.linux-x86_64-3.10/pycocotools\nrunning build_ext\ncythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/packages/pycocotools-2.0.6/pycocotools/_mask.pyx\n  tree = Parsing.p_module(s, pxd, full_module_name)\n","output_type":"stream"},{"name":"stdout","text":"building 'pycocotools._mask' extension\ncreating build/temp.linux-x86_64-3.10\ncreating build/temp.linux-x86_64-3.10/common\ncreating build/temp.linux-x86_64-3.10/pycocotools\ngcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.10/site-packages/numpy/core/include -I./common -I/opt/conda/include/python3.10 -c ./common/maskApi.c -o build/temp.linux-x86_64-3.10/./common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","output_type":"stream"},{"name":"stderr","text":"./common/maskApi.c: In function â€˜rleToBboxâ€™:\n./common/maskApi.c:151:32: warning: unused variable â€˜xpâ€™ [-Wunused-variable]\n  151 |     uint h, w, xs, ys, xe, ye, xp, cc; siz j, m;\n      |                                ^~\n./common/maskApi.c: In function â€˜rleFrPolyâ€™:\n./common/maskApi.c:197:3: warning: this â€˜forâ€™ clause does not guard... [-Wmisleading-indentation]\n  197 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n      |   ^~~\n./common/maskApi.c:197:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜forâ€™\n  197 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n      |                                                      ^\n./common/maskApi.c:198:3: warning: this â€˜forâ€™ clause does not guard... [-Wmisleading-indentation]\n  198 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n      |   ^~~\n./common/maskApi.c:198:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜forâ€™\n  198 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n      |                                                      ^\n./common/maskApi.c: In function â€˜rleToStringâ€™:\n./common/maskApi.c:243:7: warning: this â€˜ifâ€™ clause does not guard... [-Wmisleading-indentation]\n  243 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n      |       ^~\n./common/maskApi.c:243:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜ifâ€™\n  243 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n      |                           ^\n./common/maskApi.c: In function â€˜rleFrStringâ€™:\n./common/maskApi.c:251:3: warning: this â€˜whileâ€™ clause does not guard... [-Wmisleading-indentation]\n  251 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n      |   ^~~~~\n./common/maskApi.c:251:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜whileâ€™\n  251 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n      |                      ^~~~\n./common/maskApi.c:259:5: warning: this â€˜ifâ€™ clause does not guard... [-Wmisleading-indentation]\n  259 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n      |     ^~\n./common/maskApi.c:259:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜ifâ€™\n  259 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n      |                                  ^~~~\n","output_type":"stream"},{"name":"stdout","text":"gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.10/site-packages/numpy/core/include -I./common -I/opt/conda/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","output_type":"stream"},{"name":"stderr","text":"pycocotools/_mask.c: In function â€˜__pyx_pf_11pycocotools_5_mask_12iouâ€™:\npycocotools/_mask.c:6140:31: warning: comparison of integer expressions of different signedness: â€˜Py_ssize_tâ€™ {aka â€˜long intâ€™} and â€˜sizâ€™ {aka â€˜long unsigned intâ€™} [-Wsign-compare]\n 6140 |     if (unlikely(!((__pyx_t_8 == __pyx_v_n) != 0))) {\n      |                               ^~\npycocotools/_mask.c:944:43: note: in definition of macro â€˜unlikelyâ€™\n  944 |   #define unlikely(x) __builtin_expect(!!(x), 0)\n      |                                           ^\n","output_type":"stream"},{"name":"stdout","text":"gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-3.10/./common/maskApi.o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -o build/lib.linux-x86_64-3.10/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\ncreating build/bdist.linux-x86_64\ncreating build/bdist.linux-x86_64/egg\ncreating build/bdist.linux-x86_64/egg/pycocotools\ncopying build/lib.linux-x86_64-3.10/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\ncopying build/lib.linux-x86_64-3.10/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\ncopying build/lib.linux-x86_64-3.10/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\ncopying build/lib.linux-x86_64-3.10/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\ncopying build/lib.linux-x86_64-3.10/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\nbyte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-310.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-310.pyc\ncreating stub loader for pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\nbyte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-310.pyc\ncreating build/bdist.linux-x86_64/egg/EGG-INFO\ncopying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\nwriting build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\ncreating dist\ncreating 'dist/pycocotools-2.0.6-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\nremoving 'build/bdist.linux-x86_64/egg' (and everything under it)\nProcessing pycocotools-2.0.6-py3.10-linux-x86_64.egg\ncreating /opt/conda/lib/python3.10/site-packages/pycocotools-2.0.6-py3.10-linux-x86_64.egg\nExtracting pycocotools-2.0.6-py3.10-linux-x86_64.egg to /opt/conda/lib/python3.10/site-packages\nAdding pycocotools 2.0.6 to easy-install.pth file\n\nInstalled /opt/conda/lib/python3.10/site-packages/pycocotools-2.0.6-py3.10-linux-x86_64.egg\nProcessing dependencies for pycocotools==2.0.6\n","output_type":"stream"},{"name":"stderr","text":"zip_safe flag not set; analyzing archive contents...\npycocotools.__pycache__._mask.cpython-310: module references __file__\nerror: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.24.3.dist-info/METADATA'\n","output_type":"stream"},{"name":"stdout","text":"Looking in links: /kaggle/working/packages/\nProcessing /kaggle/working/packages/pycocotools-2.0.6\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.6) (3.6.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.6) (1.23.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (9.5.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.6) (1.16.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (pyproject.toml): started\n  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=102202 sha256=a659b75d38dcd5f81d8121b27b95c99d297b1825ea18ed503fe2c4bf059089e2\n  Stored in directory: /root/.cache/pip/wheels/b7/83/32/99474500256e64154dfc568319411b6ff49e96e50f30d9474f\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\n  Attempting uninstall: pycocotools\n    Found existing installation: pycocotools 2.0.6\n    Uninstalling pycocotools-2.0.6:\n      Successfully uninstalled pycocotools-2.0.6\nSuccessfully installed pycocotools-2.0.6\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Dataset libraries</b>\n</div>","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport cv2\nimport yaml\nimport json\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:16.150957Z","iopub.execute_input":"2023-06-27T14:46:16.151464Z","iopub.status.idle":"2023-06-27T14:46:16.344146Z","shell.execute_reply.started":"2023-06-27T14:46:16.151421Z","shell.execute_reply":"2023-06-27T14:46:16.342690Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Dataset config</b>\n</div>","metadata":{}},{"cell_type":"code","source":"dataset_config = {\n    \"background\": {\n        \"apply_mask\": None,\n        \"label\": 0,\n        \"rgb\": (0, 0, 0),\n        \"loss_weight\": None\n    },\n    \"blood_vessel\": {\n        \"apply_mask\": True,\n        \"label\": 1,\n        \"rgb\": (255, 8, 8),\n        \"loss_weight\": None\n    },\n    \"glomerulus\": {\n        \"apply_mask\": True,\n        \"label\": 2,\n        \"rgb\": (8, 12, 255),\n        \"loss_weight\": None\n    },\n    \"unsure\": {\n        \"apply_mask\": True,\n        \"label\": 3,\n        \"rgb\": (8, 255, 20),\n        \"loss_weight\": None\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:16.345907Z","iopub.execute_input":"2023-06-27T14:46:16.346272Z","iopub.status.idle":"2023-06-27T14:46:16.354101Z","shell.execute_reply.started":"2023-06-27T14:46:16.346242Z","shell.execute_reply":"2023-06-27T14:46:16.352692Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def write_config(data: dict[dict, ...], path: str) -> None:\n    with open(path, mode=\"w\") as f:\n        yaml.safe_dump(stream=f, data=data)\n        \nwrite_config(dataset_config, __DATASET_CONFIG_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:16.357143Z","iopub.execute_input":"2023-06-27T14:46:16.357655Z","iopub.status.idle":"2023-06-27T14:46:16.370604Z","shell.execute_reply.started":"2023-06-27T14:46:16.357618Z","shell.execute_reply":"2023-06-27T14:46:16.369272Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Dataset ðŸª¢</b>\n</div>","metadata":{}},{"cell_type":"code","source":"from typing import Tuple\n\nclass HuBMAPDataset(Dataset):\n    def __init__(self, \n                 annotation_path: str,\n                 image_path: str, \n                 config_path: str):\n        self.__image_path = image_path\n        self.__samples = self.parse_jsonl(annotation_path)\n        self.__config = self.load_config(config_path)\n    \n    def __len__(self) -> int:\n        return len(self.__samples)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, np.ndarray]:\n        image = self.__get_image(idx)\n        mask = self.__get_mask(idx)\n    \n        image = torch.tensor(image, dtype=torch.uint8).permute(2, 0, 1)\n        mask = torch.tensor(mask, dtype=torch.float32) \n    \n        return image, mask\n\n        \n    @staticmethod\n    def parse_jsonl(path: str) -> list[dict, ...]:\n        with open(path, 'r') as json_file:\n            jsonl_labels = [\n                json.loads(line)\n                for line in notebook.tqdm(\n                    json_file, desc=\"Processing polygons\", total=1633\n                )\n            ]\n        return jsonl_labels\n\n    @staticmethod\n    def load_config(path: str) -> dict:\n        with open(path, mode=\"r\") as f:\n            data = yaml.load(stream=f, Loader=yaml.SafeLoader)\n        return data\n    \n    def __get_image_path(self, id: str) -> str:\n        path = os.path.join(\n            self.__image_path, f\"{id}.tif\"\n        )\n        return path\n    \n    def __get_image(self, idx: int) -> np.ndarray:\n        id = self.__samples[idx][\"id\"]\n        image_path = self.__get_image_path(id)\n        image = Image.open(image_path)\n        image = np.asarray(image)\n        return image\n            \n    def __get_mask(self, idx: int) -> np.ndarray:\n        mask = np.zeros((512, 512), dtype=np.uint8)\n        annotations = self.__samples[idx][\"annotations\"]\n        \n        for vessel in annotations:\n            vessel_type = vessel[\"type\"] \n            config = self.__config[vessel_type]\n            \n            if config[\"apply_mask\"]:\n                coordinates = np.array(vessel[\"coordinates\"])\n                mask = cv2.fillPoly(\n                    mask, pts=coordinates,\n                    color=config[\"rgb\"]\n                )\n        return mask","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:16.372248Z","iopub.execute_input":"2023-06-27T14:46:16.372744Z","iopub.status.idle":"2023-06-27T14:46:16.393638Z","shell.execute_reply.started":"2023-06-27T14:46:16.372698Z","shell.execute_reply":"2023-06-27T14:46:16.392284Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Let's check dataset</b>\n</div>","metadata":{}},{"cell_type":"code","source":"dataset = HuBMAPDataset(__ANNOTATION_PATH, __TRAIN_PATH, __DATASET_CONFIG_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:16.394812Z","iopub.execute_input":"2023-06-27T14:46:16.395171Z","iopub.status.idle":"2023-06-27T14:46:21.961293Z","shell.execute_reply.started":"2023-06-27T14:46:16.395144Z","shell.execute_reply":"2023-06-27T14:46:21.960024Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing polygons:   0%|          | 0/1633 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff512353a9a14d2eab8bd48b77897d8c"}},"metadata":{}}]},{"cell_type":"code","source":"image, mask = dataset[0]\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nax1.imshow(image)\nax2.imshow(mask)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T14:46:21.963198Z","iopub.execute_input":"2023-06-27T14:46:21.963668Z","iopub.status.idle":"2023-06-27T14:46:23.490741Z","shell.execute_reply.started":"2023-06-27T14:46:21.963636Z","shell.execute_reply":"2023-06-27T14:46:23.489214Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m image, mask \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43max1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ax2\u001b[38;5;241m.\u001b[39mimshow(mask)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5658\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   5659\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[1;32m   5660\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   5661\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   5662\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5663\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5665\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5666\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5668\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 512, 512) for image data"],"ename":"TypeError","evalue":"Invalid shape (3, 512, 512) for image data","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Train </b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"In this script, you need to define your own model architecture in the MyModel class and modify the loss function and optimizer based on your specific task. Make sure to adjust the file paths to point to your actual dataset and configuration files.\n\nThe script performs a training loop over the specified number of epochs, with a separate validation step after each epoch. It calculates and prints the average training and validation losses for monitoring the model's performance during training. Finally, the trained model is saved to a file.\n\nPlease customize the script according to your specific needs, including any additional preprocessing steps, model architecture, loss function, and optimization algorithm.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nfrom sklearn.model_selection import train_test_split\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # Define your model layers here\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 1, kernel_size=1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        # Implement the forward pass of your model here\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n# Initialize your dataset\n# annotation_path = \"/kaggle/input/hubmap-hacking-the-human-vasculature/polygons.jsonl\"\n# image_path = \"/kaggle/input/hubmap-hacking-the-human-vasculature/train/0006ff2aa7cd.tif\"\n# config_path = \"/path/to/config.yaml\"\n# dataset = HuBMAPDataset(annotation_path, image_path, config_path)\n\n#Split the dataset into train and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n# Define data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n# Initialize your model\nmodel = MyModel()\n\n# Define your loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n\n    # Training\n    model.train()\n    for images, masks in train_loader:\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n        \n        # Convert the input tensor to float32\n        images = images.float()\n        \n        # Convert model parameters to float32\n        model.float()\n\n        # Forward pass\n        outputs = model(images)\n\n        # Calculate loss\n        loss = criterion(outputs, masks)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        for images, masks in val_loader:\n            images = images.to(device)\n            masks = masks.to(device)\n            \n            # Convert the input tensor to float32\n            images = images.float()\n            \n             # Convert model parameters to float32\n            model.float()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Calculate loss\n            loss = criterion(outputs, masks)\n\n            val_loss += loss.item() * images.size(0)\n\n    # Calculate average losses\n    train_loss /= len(train_dataset)\n    val_loss /= len(val_dataset)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T15:01:33.809620Z","iopub.execute_input":"2023-06-27T15:01:33.810094Z","iopub.status.idle":"2023-06-27T15:02:05.522753Z","shell.execute_reply.started":"2023-06-27T15:01:33.810059Z","shell.execute_reply":"2023-06-27T15:02:05.520948Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     93\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [32, 1, 256, 256] , target: [32, 512, 512]"],"ename":"RuntimeError","evalue":"size mismatch (got input: [32, 1, 256, 256] , target: [32, 512, 512]","output_type":"error"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nfrom sklearn.model_selection import train_test_split\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # Define your model layers here\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        # Implement the forward pass of your model here\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n# Initialize your dataset\n# annotation_path = \"/kaggle/input/hubmap-hacking-the-human-vasculature/polygons.jsonl\"\n# image_path = \"/kaggle/input/hubmap-hacking-the-human-vasculature/train/0006ff2aa7cd.tif\"\n# config_path = \"/path/to/config.yaml\"\n# dataset = HuBMAPDataset(annotation_path, image_path, config_path)\n\n#Split the dataset into train and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n# Define data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n# Initialize your model\nmodel = MyModel()\n\n# Define your loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n\n    # Training\n    model.train()\n    for images, masks in train_loader:\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n        \n        # Convert the input tensor to float32\n        images = images.float()\n\n        # Forward pass\n        outputs = model(images)\n\n        # Resize the output tensor to match the target mask's size\n        outputs = F.interpolate(outputs, size=masks.shape[2:], mode='bilinear', align_corners=False)\n\n        # Calculate loss\n        loss = criterion(outputs, masks)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        for images, masks in val_loader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            # Convert the input tensor to float32\n            images = images.float()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Resize the output tensor to match the target mask's size\n            outputs = F.interpolate(outputs, size=masks.shape[2:], mode='bilinear', align_corners=False)\n\n            # Calculate loss\n            loss = criterion(outputs, masks)\n\n            val_loss += loss.item() * images.size(0)\n\n\n    # Calculate average losses\n    train_loss /= len(train_dataset)\n    val_loss /= len(val_dataset)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T15:07:21.911674Z","iopub.execute_input":"2023-06-27T15:07:21.912139Z","iopub.status.idle":"2023-06-27T15:07:34.253178Z","shell.execute_reply.started":"2023-06-27T15:07:21.912103Z","shell.execute_reply":"2023-06-27T15:07:34.251744Z"},"trusted":true},"execution_count":26,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Resize the output tensor to match the target mask's size\u001b[39;00m\n\u001b[1;32m     88\u001b[0m outputs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(outputs, size\u001b[38;5;241m=\u001b[39mmasks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[26], line 37\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Implement the forward pass of your model here\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    val_loss = 0.0\n\n    # Training\n    model.train()\n    for images, masks in train_loader:\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n\n        # Convert the input tensor to float32\n        images = images.float()\n\n        # Convert model parameters to float32\n        model.float()\n\n        # Forward pass\n        outputs = model(images)\n\n        # Calculate loss\n        loss = criterion(outputs, masks)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        for images, masks in val_loader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            # Convert the input tensor to float32\n            images = images.float()\n\n            # Convert model parameters to float32\n            model.float()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Calculate loss\n            loss = criterion(outputs, masks)\n\n            val_loss += loss.item() * images.size(0)\n\n    # Calculate average losses\n    train_loss /= len(train_dataset)\n    val_loss /= len(val_dataset)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T15:00:08.088561Z","iopub.execute_input":"2023-06-27T15:00:08.089916Z","iopub.status.idle":"2023-06-27T15:00:26.072531Z","shell.execute_reply.started":"2023-06-27T15:00:08.089855Z","shell.execute_reply":"2023-06-27T15:00:26.070669Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, masks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[23], line 36\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Implement the forward pass of your model here\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ababaa; font-family:verdana; color: #fffFFF; border: 2px #ababab solid\">\n    <b>Submission ðŸ’Œ</b>\n</div>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #f0c7c7; font-family:verdana; color: #a63c3c; border: 2px #a63c3c solid\">\n    <b>id, height, width, prediction_string</b>\n    <ul style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">\n        <li>id - identifier of the image that came to the input of the neural network.</li>\n        <li>height - image height (constant value equal to 512).</li> \n        <li>width - image width (constant value equal to 512).</li> \n        <li>prediction_string:\n            <ul style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">\n                <li>label - label class constant value equal to 0 (at least as I understand it, correct me if I'm wrong)</li>\n                <li>confidence - the confidence of the model that this object or instance belongs to the target class. That is, your model will give a mask at the output, where each mask will have the probability that this particular mask belongs to the desired class. It's like the probability of a model belonging to an object to a class. In fact, this is a probabilistic membership score that always appears when it comes to classification.</li>  \n            </ul>\n        </li> \n    </ul>\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"import base64\nimport numpy as np\nimport torch\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\nimport pandas as pd\nimport torchvision.transforms as T","metadata":{"execution":{"iopub.status.busy":"2023-06-27T00:12:00.036395Z","iopub.execute_input":"2023-06-27T00:12:00.036793Z","iopub.status.idle":"2023-06-27T00:12:00.280840Z","shell.execute_reply.started":"2023-06-27T00:12:00.036762Z","shell.execute_reply":"2023-06-27T00:12:00.279979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncodeBinaryMask:\n    @staticmethod\n    def __checking_mask(mask: np.ndarray) -> np.ndarray:\n        if mask.dtype != np.bool:\n            raise ValueError(\n                \"expects a binary mask, received dtype == %s\" %\n                mask.dtype\n            )\n        return mask\n\n    @staticmethod\n    def __convert_mask(mask: np.ndarray):\n        mask_to_encode = mask.astype(np.uint8)\n        mask_to_encode = np.asfortranarray(mask_to_encode)\n        return mask_to_encode\n\n    @staticmethod\n    def __compress_encode(encoded_mask) -> t.Text:\n        binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n        base64_str = base64.b64encode(binary_str)\n        return base64_str\n\n    def __call__(self, mask: np.ndarray) -> t.Text:\n        mask = self.__checking_mask(mask)\n        mask_to_encode = self.__convert_mask(mask)\n        encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n        base64_str = self.__compress_encode(encoded_mask)\n        return base64_str\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T00:43:13.358887Z","iopub.execute_input":"2023-06-27T00:43:13.359563Z","iopub.status.idle":"2023-06-27T00:43:13.373037Z","shell.execute_reply.started":"2023-06-27T00:43:13.359503Z","shell.execute_reply":"2023-06-27T00:43:13.372016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Submission:\n    def __init__(self, dirpath: str, model: torch.nn.Module):\n        self.__eval_transforms = self.get_transforms()\n        self.__model = model\n        self.__encoder = EncodeBinaryMask()\n        self.__dirpath = dirpath\n        self.__filenames = os.listdir(dirpath)\n        \n        self.__submission_dict = {\n            \"id\": [],\n            \"height\": [],\n            \"width\": [],\n            \"prediction_string\": []\n        }\n        \n        self.submission = None\n    \n    @staticmethod\n    def get_transforms():\n        return T.Compose([\n            T.ToTensor(),\n            T.Resize(size=(512, 512)),\n            T.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.__filenames)\n\n    def __get_columns(self) -> None:\n        for filename in self.__filenames:\n            path = self.__get_image_path(filename)\n            image = self.__get_image(path)\n            masks = self.__forward(image)\n            identifier, height, width, prediction_string = self.__get_cells(filename, masks)\n            self.__update_columns(identifier, height, width, prediction_string)\n\n    def __update_columns(self, identifier: str, height: int, width: int, prediction_string: str) -> None:\n        self.__submission_dict[\"id\"].append(identifier)\n        self.__submission_dict[\"height\"].append(height)\n        self.__submission_dict[\"width\"].append(width)\n        self.__submission_dict[\"prediction_string\"].append(prediction_string)\n\n    def __get_cells(self, filename: str, masks: list):\n        prediction_string = \"\"\n        prediction_string = self.__get_prediction_string(masks, prediction_string)\n        identifier = filename.split(\".\")[0]\n        height, width = mask.shape\n        return identifier, height, width, prediction_string\n\n    def __get_prediction_string(self, masks: list, prediction_string: str) -> str:\n        \"\"\"\n        If the neural network did not find the target structure,\n        then we will return an empty prediction_string.\n        \n        However, the columns:\n            id, height, width - must be present for all test images!!!\n        \"\"\"\n        \n        if masks:\n            for outputs in masks:\n                mask = outputs[\"mask\"].detach().permute(1,2,0).cpu().numpy()\n                mask = np.where(mask > 0.5, 1, 0).astype(np.bool)\n                base64_str = self.__encoder(mask)\n                confidence = outputs[\"confidence\"]\n                prediction_string += f\"0 {confidence} {base64_str.decode('utf-8')} \"\n        return prediction_string\n\n    def __get_image_path(self, filename: str) -> str:\n        return os.path.join(\n            self.__dirpath, filename\n        )\n\n    def __get_image(self, path: str) -> torch.Tensor:\n        image = Image.open(path)\n        image = np.asarray(image)\n        image = self.__eval_transforms(image)\n        return image\n\n    # You must implement this function to work with your custom neural network!\n    def __forward(self, image: torch.tensor) ->list:\n        \"\"\"\n        This fuction should return list with masks & confidence.\n        And each mask we shoulde encode (see EncodeBinaryMask & sample_submission file) \n        \n        outputs <- model(image) \n        outputs -> [\n                    {\"mask\": mask1, \"confidence\": confidence1},\n                    {\"mask\": mask2, \"confidence\": confidence2}, \n                    ...,\n                    {\"mask\": maskN, \"confidence\": confidenceN}\n                   ]\n                                  \n        Example:\n        \"\"\"\n        masks = self.__model(image) # Mask must have shape 1x512x512\n        return masks \n\n    def submit(self) -> None:\n        if not self.submission:\n            self.__get_columns()\n            self.submission = pd.DataFrame(self.__submission_dict)\n            self.submission = self.submission.set_index('id')\n            self.submission.to_csv(\"submission.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-25T17:19:33.804726Z","iopub.execute_input":"2023-06-25T17:19:33.805117Z","iopub.status.idle":"2023-06-25T17:19:33.82827Z","shell.execute_reply.started":"2023-06-25T17:19:33.805083Z","shell.execute_reply":"2023-06-25T17:19:33.826934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Sample model</b>\n</div>","metadata":{}},{"cell_type":"code","source":"class MyBestModel:\n    @staticmethod\n    def generate_masks(num_masks: int) -> list[dict, ...]:\n        masks = []\n        for _ in range(num_masks):\n            mask = torch.randint(0, 2, (1, 512, 512))\n            confidence = round(float(torch.rand(1)[0]), 2)\n            masks.append({\"mask\": mask, \"confidence\": confidence})\n        return masks\n        \n    def __call__(self, image) -> list[dict, ...]:\n        num_masks = torch.randint(1, 5, (1, 1))\n        masks = self.generate_masks(num_masks)\n        return masks","metadata":{"execution":{"iopub.status.busy":"2023-06-25T17:19:33.830304Z","iopub.execute_input":"2023-06-25T17:19:33.830771Z","iopub.status.idle":"2023-06-25T17:19:33.846939Z","shell.execute_reply.started":"2023-06-25T17:19:33.830729Z","shell.execute_reply":"2023-06-25T17:19:33.845798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MyBestModel()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T17:19:33.848793Z","iopub.execute_input":"2023-06-25T17:19:33.849361Z","iopub.status.idle":"2023-06-25T17:19:33.863233Z","shell.execute_reply.started":"2023-06-25T17:19:33.849322Z","shell.execute_reply":"2023-06-25T17:19:33.862264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = Submission(dirpath=__TEST_PATH, model=model)\nsub.submit()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T17:19:33.864713Z","iopub.execute_input":"2023-06-25T17:19:33.865722Z","iopub.status.idle":"2023-06-25T17:19:34.127071Z","shell.execute_reply.started":"2023-06-25T17:19:33.865658Z","shell.execute_reply":"2023-06-25T17:19:34.125945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T17:19:34.128745Z","iopub.execute_input":"2023-06-25T17:19:34.12913Z","iopub.status.idle":"2023-06-25T17:19:34.140821Z","shell.execute_reply.started":"2023-06-25T17:19:34.129097Z","shell.execute_reply":"2023-06-25T17:19:34.139655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:20px; background-color: #ffa3a3; font-family:verdana; color: #8a0f0f; border: 2px #ff0303 solid\">\n    <b>Good luck winning the competition! ðŸ¥‡</b>\n    <br>I hope this work will help you not to waste too much time and you will quickly be able to understand the data and start the competition. Good luck, friend ðŸ™ƒ<br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://media.tenor.com/BP2ZMnJf14EAAAAC/winner-winner-chicken-dinner.gif)","metadata":{}}]}